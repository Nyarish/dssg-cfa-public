{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "#\n",
    "# This notebook walks through the use and implementation of spaCy\n",
    "# as used by the DSSG-CfA team.\n",
    "#\n",
    "# Sections are: \n",
    "# Part I: Installation\n",
    "# Part II: 6 Steps to use a spaCy Model\n",
    "# Part III: Default Model\n",
    "# Part IV: Modified Model Training/Testing\n",
    "# \n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "__verion__: '0.0.1'\n",
    "__author__: 'T Tesfaye'\n",
    "__date__: 'Aug 11, 2020'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Intro </center>\n",
    "\n",
    "<span style='color:blue'> `spaCy` is one of the **most widely used** named entity recognition (NER) tools in the market. </span> Team DSSG-CfA chose to use it because of two specific reasons:\n",
    "\n",
    "1. It has strong default NER detection system, and\n",
    "2. It can be easily customized to detect labels, other than the defaults, the user is interested in.\n",
    "\n",
    "**[Here is](https://spacy.io/api/annotation#named-entities) a list of all the default entities.** A user can build on these entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Installation\n",
    "\n",
    "* Install `spaCy`: For `pip` users, run `pip install -U spacy` and for `conda` users, run `conda install -c conda-forge spacy` in your terminal command line.\n",
    "* To activate the English Model: run `python -m spacy download en_core_web_sm` in your terminal command line. Note, this model is trained on the web.\n",
    "* To activate the Portuguese Model: run `python -m spacy download pt_core_news_sm` in your terminal command line. Note, this model is trained on the news.\n",
    "\n",
    "If both installations complete with the note `Download and installation successful`, you have both the spaCy package and the specific English as well as Portuguese models. If you get error messages of other dependencies that need to be installed, go ahead and install them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: 6 Steps to use a spaCy Model\n",
    "\n",
    "These are the general steps to using a spacy model. These steps can be when running the default model vs the custom model.\n",
    "\n",
    "1. **Step 1: Decide which model to use** \n",
    "\n",
    "Each default model has four parts:\n",
    "\n",
    "    * Language: en = english\n",
    "    * Type: Model capabilities (e.g. core for general-purpose model with vocabulary, syntax, entities and word vectors, or depent for only vocab, syntax and entities).\n",
    "    * Genre: Type of text the model is trained on, e.g. web or news.\n",
    "    * Size: Model size indicator, sm, md or lg. The default is `sm` and it does pretty well. \n",
    "  \n",
    "  \n",
    "  \n",
    "   So, use these information to decide which language to use and which model to activate. **Note** It is recommended to use `en_core_web_sm` for English and `pt_core_news_sm` for Portuguese (the Portuguese model seems to only have this option).\n",
    "   \n",
    "2. **Step 2: Load the model**\n",
    "\n",
    "Once you have decided which model to use, `import spacy` and load the model using the line `spacy.load('en_core_web_sm')` for English and `spacy.load('pt_core_news_sm')` for Portuguese. It is recommended to save these models in a variable name for ease of access. That is,\n",
    "\n",
    "`nlp_en = spacy.load('en_core_web_sm')` and `nlp_pt = spacy.load(' pt_core_news_sm')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "nlp_pt = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Step 3: Apply The Model and Convert The Text to Doc**\n",
    "\n",
    "The spacy model requires texts to be in a token (losely translated as each word in a sentence for English) format in order to extract entities. Hence, apply the model and tokenize the text by running the command `nlp_en(text_of_interest)`. The output of this stage is a sequence of tokens called `doc`. Here's an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# English Text of Interest\n",
    "en_test_text = 'Jane Doe, who was born on December 12, 1990, lives in Lisbon and works at Microsoft.'\n",
    "\n",
    "# Portuguese Text of Interest (as per Google Translate)\n",
    "pt_test_text = 'Jane Doe, nascida a 12 de dezembro de 1990, vive em Lisboa e trabalha na Microsoft.'\n",
    "\n",
    "# Apply the model\n",
    "\n",
    "en_doc = nlp_en(en_test_text)\n",
    "pt_doc = nlp_pt(pt_test_text)\n",
    "type(en_doc) # to show that the returned item is a doc\n",
    "type(pt_doc) # to show that the returned item is a doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By this time, the model has been applied to the text of interest, tokenized it, and it has extracted the entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Step 4: Extract Entities**\n",
    "\n",
    "In step 3, the model has identified the entities. To access/extract the entities, run the command `.ents` on the tokenized text to return a tuple containing all the entities identified. Check [this link](https://spacy.io/api/doc) to see all the other potential attributes of a `doc` in addition to `.ents` but for now, we'll only focus on `.ents.` \n",
    "\n",
    "Here's an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Jane Doe, December 12, 1990, Lisbon, Microsoft)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(en_doc.ents)\n",
    "print(pt_doc.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the name, the date, the city, and the company are identified correctly in the English version but the date is missed in the Portuguese version (the reason is unclear)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Step 5: Operate on the Entities**\n",
    "\n",
    "We would like to get more information on the entities beyond seeing them in a tuple. For example, we want to see how they were labeled (PERSON/CITY), their character position, etc. \n",
    "\n",
    "I couldn't find a comprehensive list of entity attributes, these seem to be the most important: `ent.text`, `ent.start_char`, `ent.end_char`, `ent.label_`. **Note** `.label_` returns the actual label like 'PERSON' while `.label` returns the code for the label like '380'. `label_` is more readable to humans. \n",
    "\n",
    "Check [this link](https://spacy.io/api/span) to dig deeper into potential attributes.\n",
    "\n",
    "Let's look at these four attributes in the English and Portuguese entities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**English**\n",
      "Jane Doe PERSON 0 8\n",
      "December 12, 1990 DATE 26 43\n",
      "Lisbon GPE 54 60\n",
      "Microsoft ORG 74 83\n",
      "\n",
      "~~~~~~~//~~~~~~~~~\n",
      "\n",
      "**Portuguese**\n",
      "Jane Doe PER 0 8\n",
      "Lisboa LOC 52 58\n",
      "Microsoft ORG 73 82\n"
     ]
    }
   ],
   "source": [
    "print(\"**English**\")\n",
    "\n",
    "for ent in en_doc.ents:\n",
    "    print(ent.text, ent.label_, ent.start_char, ent.end_char)\n",
    "\n",
    "print(\"\\n~~~~~~~//~~~~~~~~~\\n\")\n",
    "print('**Portuguese**')\n",
    "for ent in pt_doc.ents:\n",
    "    print(ent.text, ent.label_, ent.start_char, ent.end_char)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that the English model and the Portuguese model return slightly different results. This could be due to the difference in the underlying model. Recommended to look into this deeper.\n",
    "\n",
    "6. **Step 6: Store your results and Visualize**\n",
    "\n",
    "You can store your results in the desired format and visualize the tokens using the `displacy` package. Feed the `doc` (i.e. tokenized text) to displacy and set the `style` argument to `='ent'` if the goal is to highlight and label the entities as shown below. Check out [this link](https://spacy.io/usage/visualizers) the other possible styles and modes of visualization.\n",
    "\n",
    "\n",
    "**Important Note** If your kernel doesn't stop running after the visualization has been rendered on your screen, feel free to click on the stop button and abort. This doesn't interrupt/disrupt any of your desired ouptputs.\n",
    "\n",
    "Here's an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Tokenization Viz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jane Doe\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", who was born on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    December 12, 1990\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", lives in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lisbon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and works at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "print(\"English Tokenization Viz\")\n",
    "\n",
    "displacy.serve(en_doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portuguese Tokenization Viz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"pt\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jane Doe\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", nascida a 12 de dezembro de 1990, vive em \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lisboa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " e trabalha na \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "print(\"Portuguese Tokenization Viz\")\n",
    "displacy.serve(pt_doc, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'> **That's all!** Using these short lines, you have extracted the default entities from your text. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Default Model\n",
    "\n",
    "The process described in part II invokes the default spaCy model. Here is an example of how to follow the above steps to apply that default model to a large detaset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store your texts in a list or in your desired format and store your output in your desired format\n",
    "input_texts = []\n",
    "output_entities = []\n",
    "\n",
    "\n",
    "# Step 1: Decide on a Model. We'll use english here to show the process\n",
    "\n",
    "# Step 2: Load the model\n",
    "nlp_model = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Step 3: Loop through your texts and apply the model\n",
    "for example in input_texts: \n",
    "    doc = nlp_model(example)\n",
    "    \n",
    "    # Step 4: Extract the entities and Step 5: Operate on the entities\n",
    "    entities = [(e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "    \n",
    "    # Step 6: Store the results. If you are hoping to use these to train the modified model, it is recommended to store them in the following nested tuple format\n",
    "    output_entities.append((text, {'entities': ents}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Modified Model Training/Testing\n",
    "\n",
    "Although the default spaCy model is strong, it can also be modified.\n",
    "\n",
    "The following function is copy pasted from [this blog](https://towardsdatascience.com/custom-named-entity-recognition-using-spacy-7140ebbb3718?gi=e6a352b438ed) which provides a step by step walkthrough.\n",
    "\n",
    "Here's a list of modifications to make to customize this function:\n",
    "\n",
    "* `training_data`: should be a list of tuples where each tuple is a single training set with the format `(text, {'entities': ents})` where `text` is the full text and `ents` is all the entities with their beginning and ending character and label as shown in the Part III example. Note `'entities'` is the key for the dictionary containing the ents.\n",
    "\n",
    "    + **Note** modifying spacy suffers from a catastrophic forgetting problem as described in [this link]. Hence, make sure the training data contains examples of both modified labels as well as default labels. \n",
    "* `all_labels`: A list of all the default and the modified labels you want the model to detect. Including extraneous labels does not impact the performance of the model while missing labels crash the model. Hence, it is recommended to include all the potential labels.\n",
    "\n",
    "    + Example: `all_labels = ['PERSON', 'NORP', 'FAC', 'ORG', 'GPE', 'LOC', 'PRODUCT', 'EVENT', 'LAND', 'PLOT NUMBER']`\n",
    "\n",
    "* `output_dir`: Provide an output directory for where you would like to save the trained model. It is recommended to save the model in its own folder for clear organization.\n",
    "* `new_model_name`: Any string of your choosing to be used as the name for the trained model\n",
    "* `n_iter`: The number of iterations you would like the model to run through. The more iterations a model performs, the better its performance (up to a certain point) but the longer it takes.\n",
    "\n",
    "\n",
    "\n",
    "Note, this function is provided for English. To adopt it for Portuguese, change the line: `nlp = spacy.blank(\"en\")` to `nlp = spacy.blank(\"pt\")`\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_my_training_data = []\n",
    "all_my_labels = []\n",
    "my_local_output_dir = ''\n",
    "\n",
    "\n",
    "def trainModifiedNERModel(training_data, all_labels, model=None, new_model_name=\"modified_ner_model_gazettes\", output_dir=local_output_dir, n_iter=100):\n",
    "    \"\"\"Set up the pipeline and entity recognizer, and train the new entity.\"\"\"\n",
    "    random.seed(0)\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "    # Add entity recognizer to model if it's not in the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    \n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner)\n",
    "        \n",
    "    # otherwise, get it, so we can add labels to it\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "    # add new entity label to entity recognizer\n",
    "    # Adding  labels shouldn't mess anything up\n",
    "    \n",
    "    \n",
    "    # Add our labels to the ner\n",
    "    for i in all_labels:\n",
    "        ner.add_label(i)\n",
    "    \n",
    "    #ner.add_label(\"LAND\")\n",
    "    \n",
    "    if model is None:\n",
    "    #if model is None:\n",
    "        optimizer = nlp.begin_training()\n",
    "    else:\n",
    "        optimizer = nlp.resume_training()\n",
    "    move_names = list(ner.move_names)\n",
    "    # get names of other pipes to disable them during training\n",
    "    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    # only train NER\n",
    "    with nlp.disable_pipes(*other_pipes), warnings.catch_warnings():\n",
    "        # show warnings for misaligned entity spans once\n",
    "        warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n",
    "\n",
    "        sizes = compounding(1.0, 4.0, 1.001)\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(training_data)\n",
    "            batches = minibatch(training_data, size=sizes)\n",
    "            losses = {}\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "            print(\"Losses\", losses)\n",
    " \n",
    "    # save model to output directory\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.meta[\"name\"] = new_model_name  # rename model\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "        \n",
    "    \n",
    "    return \"Model Trained and Saved.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of how to run this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainModifiedNERModel(training_data=all_my_training_data, all_labels=all_my_labels, output_dir=my_local_output_dir, n_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the size of your training size, running this function could take a few minutes or an over an hour. Once the training is completed, you will see these four items in your output directory: \n",
    "\n",
    "1. A folder named `ner`\n",
    "2. A folder named `vocab`\n",
    "3. A file named `meta.json`\n",
    "4. A file names `tokenizer`\n",
    "\n",
    "If you see these four items and your kernel is done running, then you can conclude that your model has finished training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the trained model is as simple as following the general instructions outlined in Part II with one exception. In Part II, Step 2, we loaded the model by running the command `spacy.load('en_core_web_sm')` for English and `spacy.load('pt_core_news_sm')` for Portuguese. However, since we are now interested in loading our own model, we will supply spacy with the path to the directory containing the modified model. In other words, we run `spacy.load(my_local_output_dir)`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "my_custom_model = spacy.load(my_local_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all the modificantion we need to make and we can follow steps 3 - 6 as outlined in Part II above to explore our trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing The Trained Model\n",
    "\n",
    "Team DSSG-CfA decided to conduct model testing manually. We assumed that the best/reference performance for a named entity recognition algorithm is a 100% since humans can accurately identify entities. Given the time constraint, we weren't able to come with an automated way of producing test sets whose default _and_ modified entities are labeled with 100% accuracy. Hence, it was faster for our team to visualize the entities using a single line of `displacy` code (as shown above) and quickly skim through the output in order to access the performance of the model. We recommend this approach if other teams are satisfied with running only a handful of tests and we recommend teams to find an automated alternative if they want to run hundreds of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_default",
   "language": "python",
   "name": "conda-env-py37_default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
