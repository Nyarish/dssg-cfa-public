{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "#\n",
    "# This notebook explains the named entity recognition tools \n",
    "# that DSSG-CfA team considered but didn't use.\n",
    "#\n",
    "# Sections are: \n",
    "# Introduction\n",
    "# Tool I: Stanza\n",
    "# Tool 2: NLTK\n",
    "# Tool 3: Snorkel\n",
    "# \n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__verion__: '0.0.1'\n",
    "__author__: 'T Tesfaye'\n",
    "__date__: 'Aug 19, 2020'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "To conduct named entity recognition (NER) on the Kenyan Gazettes, our team explored various tools before deciding to use [`spaCy`](https://spacy.io/usage/spacy-101), which is one of the most widely used free, open-source library for advanced natural language processing in Python. \n",
    "\n",
    "The other documents in this directory explain the spacy model in depth. For beginners, the notebook titled `Y_general_spaCy_beginner_tutorial.ipynb` provides a step by step walkthrough of using spacy.\n",
    "\n",
    "\n",
    "This notebook will explain the other tools our team considered but did not end up persuing due to various reasons. We hope this will help those continuing this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 1: Stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Overview of Stanza**\n",
    "\n",
    "Stanza, previously known as Stanford Named Entity Recognizer, is a collection of tools developed by Stanford University that can be used to process raw text data from its initial stages through entity recognition. It is compatible with 66 human languages. Although the backend is written in Java, it has a smooth Python interface. Detailed information about this tool and tutorials can be found [here](https://stanfordnlp.github.io/stanza/pipeline.html).\n",
    "\n",
    "Stanza reads a given text as a document. This document has numerous features including *.sentences* which returns a list of each item detected as a sentence. Then, each sentence has a *.tokens* feature which returns a list of all the tokens contained in the given sentence while each token has a *.words* feature that returns a list of tokens in the word. In the English language, a token is usually a word however, for instance, in French, the two words *de le* can be concatenated to form one token *du*. Eventually, we conduct a named entity recognition on each token.\n",
    "\n",
    "\n",
    "To use Stanza, one starts by importing stanza using their preferred Linux interface and following the instructions at this [official stanza website](https://stanfordnlp.github.io/stanza/pipeline.html). \n",
    "\n",
    "**Conclusion of Applying Stanza on Gazettes**\n",
    "\n",
    "To test the compatibility of Stanza with the gazette entries, we applied Stanza to randomly selected gazette notices and concluded that:\n",
    "\n",
    "Unique Strengths:\n",
    "\n",
    "1. Stanza does a good job of identifying names that are not American, townships that are specific to Kenya, and even P.O. Boxes and hectare sizes of lands.\n",
    "\n",
    "Unique Weaknesses:\n",
    "\n",
    "1. Despite it’s good performance, the accuracy of Stanza’s entity detection depends on the capitalization of the specific word as well as the other texts surrounding the word. The following output demonstrates that the same name `J. K. Njoroge` can be identified as a date, a person, or an organization depending on the words surrounding it and it’s capitalization. Due to this shortcoming, we could not rely on Stanza as our final NER tool.\n",
    "\n",
    "J.: I-DATE\n",
    "K.: I-DATE\n",
    "NJOROGE: E-DATE\n",
    "\n",
    "J.: B-PERSON\n",
    "K: I-PERSON\n",
    ".: I-PERSON\n",
    "Njoroge: E-PERSON\n",
    "\n",
    "J.: B-PERSON\n",
    "K: I-PERSON\n",
    ".: E-PERSON\n",
    "NJOROGE: S-ORG\n",
    "\n",
    "2. We also found that the Stanza user interface and online support system was less than desirable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 2: NLTK\n",
    "\n",
    "**Overview of NLTK**\n",
    "\n",
    "[Natural Language Toolkit (NLTK)](https://www.nltk.org/) is a platform for building Python programs to work with human language data. It is one of the most widely used named entity recognition tools on the market. One can follow [this tutorial](https://www.digitalocean.com/community/tutorials/how-to-work-with-language-data-in-python-3-using-the-natural-language-toolkit-nltk) to install and to start working with NLTK.\n",
    "\n",
    "**Conclusion of Applying NLTK on Gazettes**\n",
    "\n",
    "After experimenting with NLTK on randomly selected gazette section, we concluded the following:\n",
    "\n",
    "Unique Strengths:\n",
    "\n",
    "* NLTK has a strong multi-tokenization tool. For instance, a user can easily create a custom token such as \"title No.\" and train the NLTK model to recognize this phrase as one token which is particularly helpful in recognizing LAND REGISTRATION numbers from the gazettes. multi-tokenization is slightly complicated in spaCy.\n",
    "\n",
    "\n",
    "Weaknesses\n",
    "* The approach required to create a modified NER model in NLTK is more cumborsome than that of spaCy. This is the main reason our team chose spaCy than NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 3: Snorkel\n",
    "\n",
    "**Overview of Snorkel**\n",
    "\n",
    "\n",
    "Snorkel is a system for programmatically building and managing training datasets without manual labeling. Check [their website](https://www.snorkel.org/get-started/) for more detail and [their github page](https://github.com/snorkel-team) to find tutorials.\n",
    "\n",
    "**Conclusion of Applying Snorkel on Gazettes**\n",
    "After experimenting with Snorkel on randomly selected gazette section, we concluded the following:\n",
    "\n",
    "Unique Strengths\n",
    "* Snorkel is an advanced tool that allows us to generate numerous labeled training data using few hand labeled data.\n",
    "\n",
    "Weaknesses\n",
    "* Due to lack of time, our team could not explore the full capabilities of Snorkel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "After considering these three tools (Stanza, NLTK, and Snorkel), our team decided to use `spaCy` due to the following reasons:\n",
    "\n",
    "* `spaCy` provides a strong default NER system that identifies entities such as Person, Organization, and Date.\n",
    "* `spaCy` is easily customizable. A modified model can easily be trained using custom training sets. We used Land Registration Act notices to train a model that recognizes entities such as \"Land Size\" and \"Land Registration Number.\"\n",
    "* `spaCy` has ample support online.\n",
    "* `spaCy` is free and open source hence it would not place constraints on our partners' financial resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_default",
   "language": "python",
   "name": "conda-env-py37_default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
