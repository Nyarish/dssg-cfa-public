{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# \n",
    "# This notebook implements the modified spaCy NER training on\n",
    "# Kenyan gazettes using the helper functions.\n",
    "# \n",
    "# --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TO_HELPER = '/home/dssg-cfa/notebooks/dssg-cfa-public/C_build_ner_model/helper_functions/'\n",
    "\n",
    "import os\n",
    "os.chdir(DIR_TO_HELPER)\n",
    "\n",
    "import A_spacy_model_training_helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change to the right directory to get the modified training data and import the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dssg-cfa/notebooks/dssg-cfa-public/C_build_ner_model\n",
      "/home/dssg-cfa/notebooks/dssg-cfa-public\n",
      "/home/dssg-cfa/notebooks\n",
      "/home/dssg-cfa\n",
      "/home\n",
      "/\n"
     ]
    }
   ],
   "source": [
    "# Change this directory to the root of your folder that contains the modified labels ##TO CHANGE TO DO BEFORE FINAL\n",
    "ROUTETOROOTDIR = '/home/dssg-cfa/notebooks/dssg-cfa/'\n",
    "IMPORTSCRIPTSDIR = ROUTETOROOTDIR + \"pdf_to_text/Post-Processing/py_files\"\n",
    "\n",
    "import os\n",
    "def returnToRoot():\n",
    "    works = True\n",
    "    while works:\n",
    "        get_ipython().run_line_magic('cd', '..')\n",
    "        if os.getcwd() == \"/\":\n",
    "            works = False\n",
    "            \n",
    "returnToRoot()\n",
    "os.chdir(IMPORTSCRIPTSDIR)\n",
    "\n",
    "import trainingDataForSpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Get Modified Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 151 Land Registration Act gazettes 2000-2019. We will use 30 - 110 as training data and the rest as testing data\n",
    "\n",
    "num_training_gazettes = list(range(30, 110))\n",
    "\n",
    "# Collect the modified labels extracted using regexes\n",
    "modified_label_trainings = []\n",
    "for i in num_training_gazettes:\n",
    "    training = trainingDataForSpaCy.exportTrainData(i)\n",
    "    modified_label_trainings += training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Get Default Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "default_label_trainings = []\n",
    "\n",
    "# Loop through each example in the modified label trainings set, tokenize the example, \n",
    "# extract its entities, and append to the default_label_trainings list in the desired tuple/dict format\n",
    "for example in modified_label_trainings:\n",
    "    text = example[0]\n",
    "    reinfocing_nlp_model = spacy.load(\"en_core_web_sm\")\n",
    "    doc = reinfocing_nlp_model(text)\n",
    "    ents = [(e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "    default_label_trainings.append((text, {'entities': ents}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Combine Default and Modified Labels\n",
    "\n",
    "Each training text has the modified labels (such as LAND SIZE) extracted manually.\n",
    "But, the same text also needs to run through the default spaCy NER model to counteract the catastrophic forgetting\n",
    "problem described [here](https://explosion.ai/blog/pseudo-rehearsal-catastrophic-forgetting) https://explosion.ai/blog/pseudo-rehearsal-catastrophic-forgetting. Hence, for each text, we will combine the default and the modified labels while also removing duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_data = A_spacy_model_training_helper.getDefaultAndModifiedLabels(default_label_trainings=default_label_trainings, modified_label_trainings=modified_label_trainings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Get all the labels\n",
    "\n",
    "Collect all the modified labels such as (LAND SIZE) and the default labels in one list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_labels = ['OWNER', 'OWNER ADDRESS', 'OWNERSHIP STATUS', 'DEED STATUS', 'LAND SIZE', 'TITLE NUMBER', 'LR NUMBER', 'PLOT NUMBER', 'GRANT NUMBER', 'LAND REGISTRATION', 'ID', 'DISTRICT']\n",
    "\n",
    "all_labels = A_spacy_model_training_helper.getAllLabels(modified_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV: Train The Model\n",
    "\n",
    "Now that we have all the necessary parameters, we will train the model. Note, the larger the training data and/or the longer the number of iterations is, the training process could take up to several hours. We recommend starting with a few training sets (eg 10) and shorter iteration (eg 5) to make sure everything works. Once all the bugs are fixed, the user can add their entire training set, increase the iteration, and let this notebook run for hours while checking on it occasionally. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37_default/lib/python3.7/site-packages/spacy/language.py:639: UserWarning: [W033] Training a new parser or NER using a model with no lexeme normalization table. This may degrade the performance of the model to some degree. If this is intentional or the language you're using doesn't have a normalization table, please ignore this warning. If this is surprising, make sure you have the spacy-lookups-data package installed. The languages with lexeme normalization tables are currently: da, de, el, en, id, lb, pt, ru, sr, ta, th.\n",
      "  **kwargs\n",
      "/anaconda/envs/py37_default/lib/python3.7/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"WHEREAS Lucy Wambui Njoroge (ID/3066153), of P.O. ...\" with entities \"[(188, 202, 'LAND SIZE'), (270, 314, 'LAND REGISTR...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/anaconda/envs/py37_default/lib/python3.7/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"WHEREAS Peter Nyaranga Ouko (ID/34233939), of P.O....\" with entities \"[(188, 199, 'LAND SIZE'), (271, 309, 'LAND REGISTR...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/anaconda/envs/py37_default/lib/python3.7/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"WHEREAS Charles Saiton Kishare (ID/0800145), is re...\" with entities \"[(141, 152, 'LAND SIZE'), (221, 257, 'LAND REGISTR...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/anaconda/envs/py37_default/lib/python3.7/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"WHEREAS Peter Maina Ngugi (ID/8507836), of P.O. Bo...\" with entities \"[(271, 303, 'LAND REGISTRATION'), (411, 415, 'DEED...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/anaconda/envs/py37_default/lib/python3.7/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"WHEREAS (1) Janet Rurii Mathini (ID/0798286) and (...\" with entities \"[(325, 356, 'LAND REGISTRATION'), (464, 468, 'DEED...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/anaconda/envs/py37_default/lib/python3.7/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"WHEREAS Rachel Wanjiku Gichia Titus (ID/1603255), ...\" with entities \"[(196, 209, 'LAND SIZE'), (277, 312, 'LAND REGISTR...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/anaconda/envs/py37_default/lib/python3.7/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"WHEREAS Njogu Kimani Kibui, the personal represent...\" with entities \"[(187, 199, 'LAND SIZE'), (270, 302, 'LAND REGISTR...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/anaconda/envs/py37_default/lib/python3.7/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"WHEREAS Joshua Mutua Ireri (ID/0942652), of P.O. B...\" with entities \"[(166, 178, 'LAND SIZE'), (245, 276, 'LAND REGISTR...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/anaconda/envs/py37_default/lib/python3.7/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"WHEREAS Daniel Macharia Wahome (ID/5485671), of P....\" with entities \"[(195, 209, 'LAND SIZE'), (281, 330, 'LAND REGISTR...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/anaconda/envs/py37_default/lib/python3.7/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"WHEREAS (1) Daniel Kuria Njuguna (ID/4878527) and ...\" with entities \"[(255, 267, 'LAND SIZE'), (337, 367, 'LAND REGISTR...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/anaconda/envs/py37_default/lib/python3.7/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"WHEREAS Dishon Mutegi Kimani (ID/13501949), of P.O...\" with entities \"[(199, 212, 'LAND SIZE'), (282, 312, 'LAND REGISTR...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 1502.9020709670606}\n",
      "Losses {'ner': 563.3188366908921}\n",
      "Losses {'ner': 1509.3486651967542}\n",
      "Losses {'ner': 1127.9975190023288}\n",
      "Losses {'ner': 1037.4348122394433}\n",
      "Losses {'ner': 1285.9800633426821}\n",
      "Losses {'ner': 1081.7067437495537}\n",
      "Losses {'ner': 1238.3429500226875}\n",
      "Losses {'ner': 907.386288132497}\n",
      "Losses {'ner': 815.4118899555644}\n",
      "Saved model to /home/dssg-cfa/notebooks/dssg-cfa-public/C_build_ner_model/model_outputs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Model Trained and Saved.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Change this directory to where you would like the output of the model to be stored\n",
    "local_output_dir = '/home/dssg-cfa/notebooks/dssg-cfa-public/C_build_ner_model/model_outputs/'\n",
    "\n",
    "A_spacy_model_training_helper.trainModifiedNERModel(training_data=all_training_data, all_labels=all_labels, model=None, new_model_name=\"modified_ner_model_on_gazettes\", output_dir=local_output_dir, n_iter=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DONE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_default",
   "language": "python",
   "name": "conda-env-py37_default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
