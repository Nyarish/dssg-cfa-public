{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Create training data for our SpaCy model in the form specified in the below chunks.\n",
    "# \n",
    "# Written primarily by Robbie thus far.\n",
    "# -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATA_3 = [\n",
    "#     (sample_gazette_1, {\n",
    "#         'entities': \n",
    "#         [(12, 35, 'OWNER'), (44, 68, 'OWNER 2'), (78, 98, 'OWNER ADDRESS'), (151, 176, 'OWNERSHIP'), (230, 259, 'LAND SIZE'), (325, 349, 'LAND TITLE'), (457, 461, 'DEED STATUS')]\n",
    "#     }),\n",
    "#     (sample_gazette_1, {\"entities\": ents_1}),\n",
    "#     (sample_gazette_2, {\"entities\":\n",
    "#     [(8, 28, 'OWNER'), (33, 47, 'OWNER ADDRESS'), (110, 125, 'OWNERSHIP'), (179, 208, 'LAND SIZE'), (274, 302, 'LAND TITLE'), (410, 414, 'DEED STATUS')]                   \n",
    "#     }),\n",
    "#     (sample_gazette_2, {\"entities\": ents_2}),\n",
    "\n",
    "#     (sample_gazette_3, {'entities': [(8, 27, 'OWNER'), (32, 52, 'OWNER ADDRESS'), (105, 130, 'OWNERSHIP'), (184, 212, 'LAND SIZE'), (278, 312, 'LAND TITLE'), (420, 424, 'DEED STATUS')]    \n",
    "#                        }),\n",
    "    \n",
    "#     (sample_gazette_3, {\"entities\": ents_3}),\n",
    "#     (sample_gazette_4, {\"entities\": [(12, 35, 'OWNER'), (44, 66, 'OWNER 2'), (76, 96, 'OWNER ADDRESS'), (149, 181, 'OWNERSHIP'), (228, 255, 'LAND SIZE'), (321, 346, 'LAND TITLE'), (454, 458, 'DEED STATUS')]\n",
    "#                        }),\n",
    "#     (sample_gazette_4, {\"entities\": ents_4}),\n",
    "    \n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format: \n",
    "List, with one entry for each text in the train set. Each item in the list is a tuple with\n",
    "\n",
    "    1) the text itself\n",
    "    \n",
    "    2) a dictionary with one entry\n",
    "    \n",
    "        key: only one, always just the string 'entities'\n",
    "        \n",
    "        value: a list, with one item for each flagged entity. Each item is a thruple with\n",
    "        \n",
    "            1) start index of entity within text\n",
    "            \n",
    "            2) end index of entity within text\n",
    "            \n",
    "            3) categorization of said entity (i.e. 'PERSON')\n",
    "            \n",
    "Later in this document, when we mention \"the tuple required for spaCy training data, we are referring to the three-tuple at the bottom of this list: \n",
    "\n",
    "(start index of entity within text, end index of entity within text, categorization of said entity (i.e. 'PERSON'))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for others to use this script, it will help to change this variable to\n",
    "# whatever the route it to the root of your dssg-cfa folder.\n",
    "ROUTETOROOTDIR = '/home/dssg-cfa/notebooks/dssg-cfa-public/'\n",
    "IMPORTSCRIPTSDIR = ROUTETOROOTDIR + \"util/py_files\"\n",
    "UTILDIR = ROUTETOROOTDIR + 'util'\n",
    "JSONSDIR = ROUTETOROOTDIR + 'A_pdf_to_text/jsons_ke_gazettes/'\n",
    "CSVTRAINDIR = ROUTETOROOTDIR + 'B_text_preprocessing/csv_outputs_train/'\n",
    "CSVTESTDIR = ROUTETOROOTDIR + 'B_text_preprocessing/csv_outputs_test/'\n",
    "import os            \n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "os.chdir(IMPORTSCRIPTSDIR)\n",
    "import retoolingSegmentation\n",
    "import orderingText\n",
    "import setup\n",
    "import readingJsonsBulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListOfCsvs(filepath):\n",
    "    \"\"\"Get a list of all filenames of entity-containing csvs.\n",
    "    \n",
    "    args:\n",
    "    filepath: the filepath to the directory to search.\n",
    "    \n",
    "    returns: a list of all filenames in said directory.\"\"\"\n",
    "    \n",
    "    os.chdir(filepath)\n",
    "    ret = !ls\n",
    "    return ret\n",
    "\n",
    "# load all filenames into global variables\n",
    "listOfCsvsNew = getListOfCsvs(CSVTRAINDIR)    # this is generally our training and validation sets\n",
    "listOfCsvsOld = getListOfCsvs(CSVTESTDIR)    # this is generally our test set (non-LRA segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readProcessedGazette(gazetteNum, newOnly = True):\n",
    "    \"\"\"Read the csv of a processed gazette into a Pandas dataframe.\n",
    "    \n",
    "    args:\n",
    "    gazetteNum: the index of the csv to pull.\n",
    "    newOnly: If True, pull from the csvs in CSVTRAINDIR (new) (train set) (LRA only).\n",
    "        Otherwise, pull from the csvs in CSVTESTDIR (new and old) (test set) (all land segs).\n",
    "        \n",
    "    returns: a pandas dataframe representing a pre-processed gazette.\"\"\"\n",
    "    \n",
    "    if newOnly:\n",
    "        os.chdir(CSVTRAINDIR)\n",
    "        df = pd.read_csv(listOfCsvsNew[gazetteNum])\n",
    "    else:\n",
    "        os.chdir(CSVTESTDIR)\n",
    "        df = pd.read_csv(listOfCsvsOld[gazetteNum])\n",
    "    return df\n",
    "\n",
    "def getColAsSeries(df, colString):\n",
    "    \"\"\"Given a pandas dataframe and a string representing the name of a column, return that column as a series.\"\"\"\n",
    "    \n",
    "    return df[[colString]][colString]\n",
    "\n",
    "def getMaskOfGoodCols(df):\n",
    "    \"\"\"Return an np array of booleans, with true for each entry in our pandas df that we want to process.\n",
    "    We only want to process rows with inner text of length at least 100.\n",
    "    \n",
    "    args: \n",
    "    df: pandas df representing one regex-extracted entites csv.\n",
    "    \n",
    "    returns: a mask representing rows we wish to process.\"\"\"\n",
    "    \n",
    "    textArr = getColAsSeries(df, 'inner text')\n",
    "    longEnough = np.array([len(str(text)) > 100 for text in textArr])\n",
    "\n",
    "    return longEnough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of strings which are typically found in company names.\n",
    "COMPANY_STRS = ['Limited', 'Liability', 'Company', 'LLC', 'Ltd', 'Partnership', 'PLP', 'Incorporated', 'Inc'\n",
    "                       'Public', 'PLC', 'Corporation', 'Company', 'Foundation', 'Comission', 'Bank', 'Group']\n",
    "\n",
    "def checkCompany(text):\n",
    "    \"\"\"Check to see if a string looks like it is the name of a company.\n",
    "    \n",
    "    args: \n",
    "    text: the string to check for company-ness.\n",
    "    \n",
    "    returns: True if text contains any of the strings found in COMPANY_STRS (global),\n",
    "        False otherwise.\"\"\"\n",
    "    \n",
    "    for string in COMPANY_STRS:\n",
    "        if string in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def getOwnerTuple(series):\n",
    "    \"\"\"Get the three-tuple required for spaCy training data for OWNER.\n",
    "    Extracts the owner using our preprocessing csv.\n",
    "    \n",
    "    args:\n",
    "    series: row of a a pandas dataframe representing a pre-processed gazette.\n",
    "    \n",
    "    returns: a list of three-tuples required for spaCy training data (could be empty).\"\"\"\n",
    "    \n",
    "    resulting_names = []\n",
    "    \n",
    "    namestr = series['name']\n",
    "    innerText = series['inner text']\n",
    "    if type(namestr) == float:\n",
    "        #no name\n",
    "        return []\n",
    "    if innerText.find('(4)') != -1:\n",
    "        return fourNames(series)\n",
    "    if innerText.find('(3)') != -1:\n",
    "        return threeNames(series)\n",
    "    if innerText.find('(2)') != -1:\n",
    "        return twoNames(series)\n",
    "    start = innerText.find(namestr)\n",
    "    \n",
    "    if checkCompany(namestr):\n",
    "        resulting_names.append((start, start + len(namestr), 'ORG'))\n",
    "    else:\n",
    "        resulting_names.append((start, start + len(namestr), 'PERSON'))\n",
    "    \n",
    "    return resulting_names\n",
    "\n",
    "\n",
    "def fourNames(series):\n",
    "    \"\"\"Helper method for getOwnerTuple(). Helps to extract names when there are four names in the entry.\n",
    "    \n",
    "    args:\n",
    "    series: row of a a pandas dataframe representing a pre-processed gazette.\n",
    "    \n",
    "    returns: a list of three-tuples required for spaCy training data (could be empty).\"\"\"\n",
    "    \n",
    "    resulting_names = []\n",
    "    \n",
    "    innerText = series['inner text']\n",
    "    names = re.search(r\"\\(1\\) (.*?), \\(2\\) (.*?), \\(3\\) (.*?) and \\(4\\) (.*?),\", innerText)\n",
    "    try:\n",
    "        name1 = names[1]\n",
    "        name2 = names[2]\n",
    "        name3 = names[3]\n",
    "        name4 = names[4]\n",
    "        start1 = innerText.find(name1)\n",
    "        start2 = innerText.find(name2)\n",
    "        start3 = innerText.find(name3)\n",
    "        start4 = innerText.find(name4)\n",
    "        \n",
    "        if checkCompany(name1):\n",
    "            resulting_names.append((start1, start1 + len(name1), 'ORG'))\n",
    "        else:\n",
    "            resulting_names.append((start1, start1 + len(name1), 'PERSON'))\n",
    "        \n",
    "        if checkCompany(name2):\n",
    "            resulting_names.append((start2, start2 + len(name2), 'ORG'))\n",
    "        else:\n",
    "            resulting_names.append((start2, start2 + len(name2), 'PERSON'))\n",
    "            \n",
    "        if checkCompany(name3):\n",
    "            resulting_names.append((start3, start3 + len(name3), 'ORG'))\n",
    "        else:\n",
    "            resulting_names.append((start3, start3 + len(name3), 'PERSON'))\n",
    "            \n",
    "        if checkCompany(name4):\n",
    "            resulting_names.append((start4, start4 + len(name4), 'ORG'))\n",
    "        else:\n",
    "            resulting_names.append((start4, start4 + len(name4), 'PERSON'))\n",
    "            \n",
    "        return resulting_names\n",
    "    \n",
    "    \n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def threeNames(series):\n",
    "    \"\"\"Helper method for getOwnerTuple(). Helps to extract names when there are three names in the entry.\n",
    "    \n",
    "    args:\n",
    "    series: row of a a pandas dataframe representing a pre-processed gazette.\n",
    "    \n",
    "    returns: a list of three-tuples required for spaCy training data (could be empty).\"\"\"\n",
    "    \n",
    "    resulting_names = []\n",
    "    \n",
    "    innerText = series['inner text']\n",
    "    names = re.search(r\"\\(1\\) (.*?), \\(2\\) (.*?) and \\(3\\) (.*?),\", innerText)\n",
    "    try:\n",
    "        name1 = names[1]\n",
    "        name2 = names[2]\n",
    "        name3 = names[3]\n",
    "        \n",
    "        start1 = innerText.find(name1)\n",
    "        start2 = innerText.find(name2)\n",
    "        start3 = innerText.find(name3)\n",
    "        \n",
    "        if checkCompany(name1):\n",
    "            resulting_names.append((start1, start1 + len(name1), 'ORG'))\n",
    "        else:\n",
    "            resulting_names.append((start1, start1 + len(name1), 'PERSON'))\n",
    "        \n",
    "        if checkCompany(name2):\n",
    "            resulting_names.append((start2, start2 + len(name2), 'ORG'))\n",
    "        else:\n",
    "            resulting_names.append((start2, start2 + len(name2), 'PERSON'))\n",
    "            \n",
    "        if checkCompany(name3):\n",
    "            resulting_names.append((start3, start3 + len(name3), 'ORG'))\n",
    "        else:\n",
    "            resulting_names.append((start3, start3 + len(name3), 'PERSON'))\n",
    "            \n",
    "        return resulting_names\n",
    "\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "\n",
    "def twoNames(series):\n",
    "    \"\"\"Helper method for getOwnerTuple(). Helps to extract names when there are two names in the entry.\n",
    "    \n",
    "    args:\n",
    "    series: row of a a pandas dataframe representing a pre-processed gazette.\n",
    "    \n",
    "    returns: a list of three-tuples required for spaCy training data (could be empty).\"\"\"\n",
    "    \n",
    "    resulting_names = []\n",
    "    \n",
    "    innerText = series['inner text']\n",
    "    names = re.search(r\"\\(1\\) (.*?) and \\(2\\) (.*?),\", innerText)\n",
    "    try:\n",
    "        name1 = names[1]\n",
    "        name2 = names[2]\n",
    "        start1 = innerText.find(name1)\n",
    "        start2 = innerText.find(name2)\n",
    "        \n",
    "        if checkCompany(name1):\n",
    "            resulting_names.append((start1, start1 + len(name1), 'ORG'))\n",
    "        else:\n",
    "            resulting_names.append((start1, start1 + len(name1), 'PERSON'))\n",
    "        \n",
    "        if checkCompany(name2):\n",
    "            resulting_names.append((start2, start2 + len(name2), 'ORG'))\n",
    "        else:\n",
    "            resulting_names.append((start2, start2 + len(name2), 'PERSON'))\n",
    "            \n",
    "        return resulting_names\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "def getOwnerAddressTuple(series):\n",
    "    \"\"\"Get the tuple required for spaCy training data for OWNER ADDRESS.\n",
    "    Extracts the address using our preprocessing csv.\n",
    "    \n",
    "    args:\n",
    "    series: row of a a pandas dataframe representing a pre-processed gazette.\n",
    "    \n",
    "    returns: a list of three-tuples required for spaCy training data (could be empty).\"\"\"\n",
    "    \n",
    "    address = series['address']\n",
    "    if type(address) == float or len(address) < 5:          #5 is a magic number\n",
    "        return []\n",
    "    innerText = series['inner text']\n",
    "    start = innerText.find(address)\n",
    "    return [(start, start + len(address), 'OWNER ADDRESS')]\n",
    "\n",
    "def getTupleTag(series, colname, tagname):\n",
    "    \"\"\"Get the tuple required for spaCy training data for any variety of columns in preprocessing.\n",
    "    \n",
    "    args:\n",
    "    series: row of a a pandas dataframe representing a pre-processed gazette.\n",
    "    colname: name of column in pre-processed csv to pull from\n",
    "    tagname: name to tag entities to.\n",
    "    \n",
    "    returns: a list of three-tuples required for spaCy training data (could be empty).\"\"\"\n",
    "    \n",
    "    text = series[colname]\n",
    "    if type(text) != str and np.isnan(text):\n",
    "        return []\n",
    "    text = orderingText.convertNoToNumbers(str(text))\n",
    "    innerText = series['inner text']\n",
    "    start = innerText.find(text)\n",
    "    return [(start, start + len(str(text)), tagname)]\n",
    "\n",
    "def getDeedStatus(innerText):\n",
    "    \"\"\"Gets the status of the deed in the text in question. \n",
    "    Returns information in tuple required for spaCy training.\n",
    "    \n",
    "    args:\n",
    "    innerText: the text of a gazette segment, minus headers and footers.\n",
    "    \n",
    "    returns: a list of three-tuples required for spaCy training data (could be empty).\"\"\"\n",
    "    \n",
    "    ret = []\n",
    "    if 'lost' in innerText:\n",
    "        start = innerText.find('lost')\n",
    "        ret.append((start, start + 4, 'DEED STATUS'))\n",
    "    if 'cancelled and of no effect' in innerText:\n",
    "        start = innerText.find('cancelled and of no effect')\n",
    "        ret.append((start, start + 26, 'DEED STATUS'))\n",
    "    return ret\n",
    "\n",
    "def getOwnershipStatus(innerText):\n",
    "    \"\"\"Gets the status of ownership in the text in question. \n",
    "    Returns information in tuple required for spaCy training.\n",
    "    \n",
    "    args:\n",
    "    innerText: the text of a gazette segment, minus headers and footers.\n",
    "    \n",
    "    returns: a list of three-tuples required for spaCy training data (could be empty).\"\"\"\n",
    "    \n",
    "    ret = []\n",
    "    strsToFind = [\"proprietor in absolute ownership\", \"proprietors in absolute ownership\",\n",
    "                  \"proprietor lessee\", \"proprietors lessee\"\n",
    "                  \"proprietor in leasehold interest\", \"proprietors in leasehold interest\",\n",
    "                  \"proprietor in freehold interest\", \"proprietors in freehold interest\"]\n",
    "    for toFind in strsToFind:\n",
    "        if toFind in innerText:\n",
    "            start = innerText.find(toFind)\n",
    "            ret.append((start, start + len(toFind), 'OWNERSHIP STATUS'))\n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOverlapsAndBadEntries(tupleTags):\n",
    "    \"\"\"Remove tuples that reprsenting taggings of entities so that no two tuples overlap\n",
    "    concerning the characters they use in the original text.\n",
    "    \n",
    "    args: \n",
    "    tupleTags: list of three-tuples in format required by spaCy for training data.\n",
    "    \n",
    "    returns: list of three-tuples in format required by spaCy for training data, overlaps removed.\"\"\"\n",
    "    \n",
    "    charsUsedOverall = set()\n",
    "    overlapTagNums = []\n",
    "    \n",
    "    #find tag num which overlaps with previous tags\n",
    "    for tagNum in range(len(tupleTags)):\n",
    "        tag = tupleTags[tagNum]\n",
    "        start = tag[0]\n",
    "        end = tag[1]\n",
    "        charsUsedOneTag = set()\n",
    "        \n",
    "        if start == -1:\n",
    "            overlapTagNums.append(tagNum)\n",
    "            continue\n",
    "        \n",
    "        for char in range(start, end):\n",
    "            charsUsedOneTag.add(char)\n",
    "        intersect = charsUsedOverall.intersection(charsUsedOneTag)\n",
    "        if len(intersect) == 0:\n",
    "            charsUsedOverall = charsUsedOverall.union(charsUsedOneTag)\n",
    "        else:\n",
    "            overlapTagNums.append(tagNum)\n",
    "    \n",
    "    #remove overlapping tags\n",
    "    for tagNum in reversed(overlapTagNums):\n",
    "        tupleTags.pop(tagNum)\n",
    "    return tupleTags\n",
    "\n",
    "def getListOfDistricts():\n",
    "    \"\"\"From the csv Kenya_districts.csv, pull a python list of Kenyan districts.\n",
    "    \n",
    "    returns: a Python list of districts in Kenya.\"\"\"\n",
    "    \n",
    "    os.chdir(UTILDIR)\n",
    "    df = pd.read_csv('Kenya_districts.csv')\n",
    "    districtsUncleaned = df[['DISTRICT']]['DISTRICT']\n",
    "    cleanDistricts = [district[:-9] for district in districtsUncleaned]\n",
    "    newDistricts = set(cleanDistricts)\n",
    "    for district in cleanDistricts:\n",
    "        if district[-4:] == \"East\" or district[-4:] == \"West\":\n",
    "            newDistricts.add(district[:-5])\n",
    "            continue \n",
    "        if district[-5:] == \"North\" or district[-5:] == \"South\":\n",
    "            newDistricts.add(district[:-6])\n",
    "    return newDistricts\n",
    "\n",
    "DISTRICTS = getListOfDistricts()\n",
    "\n",
    "def getDistrictTuple(innerText):\n",
    "    \"\"\"Pull all tuples representing districts in Kenya. \n",
    "    \n",
    "    args:\n",
    "    innerText: the text of a gazette segment, minus headers and footers.\n",
    "    \n",
    "    returns: a list of three-tuples required for spaCy training data (could be empty). \"\"\"\n",
    "    \n",
    "    ret = []\n",
    "    for district in DISTRICTS:\n",
    "        if district in innerText:\n",
    "            matches = re.finditer(district + \" District\", innerText)\n",
    "            for match in matches:\n",
    "                ret.append((match.start(), match.start() + len(district), 'DISTRICT'))\n",
    "                \n",
    "            matches = re.finditer(\"district of \" + district, innerText)\n",
    "            for match in matches:\n",
    "                ret.append((match.start() + 12, match.start() + 12 + len(district), 'DISTRICT'))\n",
    "    return ret\n",
    "\n",
    "def getLocationTuple(innerText):\n",
    "    \"\"\"Pull the phrase '(situate in ...), in the district of ...'. \n",
    "    \n",
    "    args:\n",
    "    innerText: the text of a gazette segment, minus headers and footers.\n",
    "    \n",
    "    returns: a list of three-tuples required for spaCy training data (could be empty). \"\"\"\n",
    "    \n",
    "    ret = []\n",
    "    try:\n",
    "        strToFind = re.search(r\"situate (.{8,}) in\", innerText)[1]\n",
    "        start = innerText.find(strToFind)\n",
    "        #print(start, strToFind)\n",
    "        ret.append((start, start + len(strToFind), 'LOC'))\n",
    "        return ret\n",
    "    except:\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIDtuple(nameText, firstCharI):\n",
    "    \"\"\"Pull the phrase 'ID/12312' (digits can change of course).\n",
    "    Return in tuple format required by spaCy. \n",
    "    \n",
    "    args:\n",
    "    nameText: text of a name pulled, which might also contain an ID number inside.\n",
    "    firstCharI: the index inside the original text in which the name starts.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        strToFind = re.search(r\"\\((ID/[0-9]{3,})\\)\", nameText)[1] # 3 is a magic number\n",
    "        start = nameText.find(strToFind)\n",
    "        #print(start, strToFind)\n",
    "        return (firstCharI + start, firstCharI + start + len(strToFind), 'ID')\n",
    "    except:\n",
    "        return None\n",
    "        \n",
    "def stripIDsFromPersonTuples(personTuples, innerText):\n",
    "    \"\"\"Given a list of tuples which represent the person entities in the text,\n",
    "    extract their corresponding ID numbers.\n",
    "    \n",
    "    personTuple: three tuple required by spaCy format.\n",
    "    innerText: the text of a gazette segment, minus headers and footers.\"\"\"\n",
    "    \n",
    "    ret = []\n",
    "    for tup in personTuples:\n",
    "        start, end, ID = tup\n",
    "        if ID != \"PERSON\":\n",
    "            ret.append(tup)\n",
    "            continue\n",
    "        nameText = innerText[start:end]\n",
    "        IDtuple = getIDtuple(nameText, start)\n",
    "        if IDtuple:\n",
    "            newEnd = nameText.find(\"(\")\n",
    "            ret.append((start, start + newEnd, 'PERSON'))\n",
    "            ret.append(IDtuple)\n",
    "        else:\n",
    "            ret.append(tup)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllTrainData(df):\n",
    "    \"\"\"Gets all training data required by spaCy for one preprocessing csv. \n",
    "    Returns in list format which spaCy desires.\n",
    "    \n",
    "    args:\n",
    "    df: pandas df representing one regex-extracted entites csv.\n",
    "    \n",
    "    returns: a list of tuples of the format (innerText, retDict). \n",
    "    Each list item corresponds to the data structure found at the top of this notebook.\"\"\"\n",
    "    \n",
    "    ret = []\n",
    "    mask = getMaskOfGoodCols(df)\n",
    "    for i in range(len(df)):\n",
    "        if mask[i]:\n",
    "            series = df.iloc[i,]\n",
    "            ret.append(getTrainDataOneSeries(series))\n",
    "    return ret\n",
    "\n",
    "def getTrainDataOneSeries(series):\n",
    "    \"\"\"For one series (entry) in a Pandas df, get all training data in format required by spaCy.\n",
    "    \n",
    "    args:\n",
    "    series: row of a a pandas dataframe representing a pre-processed gazette.\n",
    "    \n",
    "    returns: (innerText, retDict). This corresponds to the data structure found\n",
    "    at the top of this notebook.\"\"\"\n",
    "    \n",
    "    innerText = series['inner text']\n",
    "    value = getTupleTag(series, 'land size', 'LAND SIZE')\n",
    "    value += getTupleTag(series, 'title number', \"LAND REGISTRATION\")\n",
    "    value += getTupleTag(series, 'LR number', 'LAND REGISTRATION')\n",
    "    value += getTupleTag(series, 'plot number', \"LAND REGISTRATION\")\n",
    "    value += getTupleTag(series, 'grant number', \"LAND REGISTRATION\")\n",
    "    value += getDeedStatus(innerText)\n",
    "    value += getOwnershipStatus(innerText)\n",
    "    value += getOwnerTuple(series)\n",
    "    value += getOwnerAddressTuple(series)\n",
    "    value += getDistrictTuple(innerText)\n",
    "    value += getLocationTuple(innerText)\n",
    "    value = stripIDsFromPersonTuples(value, innerText)\n",
    "    removeOverlapsAndBadEntries(value)\n",
    "    retDict = {'entities' : value}\n",
    "    return (innerText, retDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportTrainData(csvNum, writeToTxt = False, filename = 'default', filepath = 'default'):\n",
    "    \"\"\"Return training data in spaCy format for a single pre-processing csv.\n",
    "    Export to txt if necessary.\n",
    "    \n",
    "    args:\n",
    "    csvNum: index of pre-processing csv to use.\n",
    "    writeToTxt: if true, write training data to txt format.\n",
    "    filename: name of file to write txt to\n",
    "    filepath: directory to write file to.\n",
    "    \n",
    "    returns: training data in the format shown at top of notebook.\"\"\"\n",
    "    \n",
    "    df = readProcessedGazette(csvNum)\n",
    "    trainData = getAllTrainData(df)\n",
    "    \n",
    "    if writeToTxt:\n",
    "        # deal with writing to csv if necessary\n",
    "        if filename == 'default':\n",
    "            filename = 'train_data_' + listOfCsvsNew[csvNum][9:-4]\n",
    "        if filepath == 'default':\n",
    "            filepath = 'ERROR_PICK_DIRECTORY'\n",
    "        os.chdir(filepath)\n",
    "        trainText = str(trainData)\n",
    "        setup.writeTxt(filename, trainText, filepath)\n",
    "        \n",
    "    return trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportSeriesOfTrainData(startI, endI, writeToTxt = False):\n",
    "    \"\"\"Return training data in spaCy format for a range of pre-processing csvs.\n",
    "    Export to txts if necessary.\n",
    "    \n",
    "    args:\n",
    "    startI, endI: range of indices of pre-processing csvs to use (inclusive, exclusive).\n",
    "    writeToTxt: if true, write training data to txt format.\n",
    "    \n",
    "    returns: training data in the format shown at top of notebook.\"\"\"\n",
    "    \n",
    "    ret = []\n",
    "    for i in range(startI, endI):\n",
    "        ret += exportTrainData(i)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullFound(testSet):\n",
    "    \"\"\"Debugging method. Print the entities found in a text.\"\"\"\n",
    "    \n",
    "    text = testSet[0]\n",
    "    print(text + '\\n')\n",
    "    for entry in testSet[1]['entities']:\n",
    "        start = entry[0]\n",
    "        end = entry[1]\n",
    "        print(entry[2] +\": \" + text[start:end])\n",
    "    return\n",
    "\n",
    "def skipNER(gazNum):\n",
    "    \"\"\"Debugging method. Extract entities that appear in training data.\"\"\"\n",
    "    \n",
    "    segments = exportTrainData(gazNum)\n",
    "    ret = []\n",
    "    for segment in segments:\n",
    "        segRet = []\n",
    "        text = segment[0]\n",
    "        for entry in segment[1]['entities']:\n",
    "            start = entry[0]\n",
    "            end = entry[1]\n",
    "            typeStr = entry[2]\n",
    "            itemStr = text[start:end]\n",
    "            segRet.append([typeStr, itemStr])\n",
    "        ret.append(segRet)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullOldGazetteSeg(gazetteNum, textOnly = True, \n",
    "                      titles = ['THE LAND ACT', 'THE NATIONAL LAND COMMISSION ACT', \n",
    "                                'THE ENIVONRMENTAL MANAGEMENT AND','THE LAND REGISTRATION ACT']):\n",
    "    \"\"\"Debugging method. Pull old gazette segments, containing only titles listed in titles.\"\"\"\n",
    "\n",
    "    df = readProcessedGazette(gazetteNum, newOnly = False)\n",
    "    gazetteName = listOfCsvsOld[gazetteNum]\n",
    "    if titles == 'all':\n",
    "        return df, gazetteName\n",
    "    ret = df[df['title'] == \"never gonna see this!\"]\n",
    "    for title in titles:\n",
    "        subtitlesArr = np.array(df['subtitles'])\n",
    "        titlesArr = np.array(df['title'])\n",
    "        inSubtitles = np.array([title in str(subtitlesArr[i]) for i in range(len(subtitlesArr))])\n",
    "        inTitles = np.array([title in str(titlesArr[i]) for i in range(len(titlesArr))])\n",
    "        goodEntries = np.logical_or(inSubtitles, inTitles)\n",
    "        ret = ret.append(df[goodEntries])\n",
    "    if textOnly:\n",
    "        ret1 = list(ret['text'])\n",
    "        ret2 = list(ret['inner text'])\n",
    "        if ret1 == [] or type(ret1[0]) == float:\n",
    "            return gazetteName, [], []\n",
    "        else:\n",
    "            return gazetteName, ret1, ret2\n",
    "    else:\n",
    "        return gazetteName, ret\n",
    "\n",
    "def pullRangeOfOldGazettes(startGaz, endGaz, textOnly = True,\n",
    "                           titles = ['THE LAND ACT', 'THE NATIONAL LAND COMMISSION ACT', \n",
    "                                     'THE ENIVONRMENTAL MANAGEMENT AND','THE LAND REGISTRATION ACT']):\n",
    "    \"\"\"Debugging method. Pull old gazette segments, containing only titles listed in titles.\"\"\"\n",
    "    \n",
    "    ret = []\n",
    "    for i in range(startGaz + 1, endGaz):\n",
    "        newData = pullOldGazetteSeg(i, textOnly, titles)\n",
    "        ret.append(newData)\n",
    "    return ret\n",
    "\n",
    "def inspectOldGazette(gazetteNum, titles = ['THE LAND ACT', 'THE NATIONAL LAND COMMISSION ACT', \n",
    "                                'THE ENIVONRMENTAL MANAGEMENT AND','THE LAND REGISTRATION ACT']):\n",
    "    \"\"\"Debugging method. Print output of an old gazette.\"\"\"\n",
    "    \n",
    "    name, segsFull, segsInner = pullOldGazetteSeg(gazetteNum, True, titles)\n",
    "    print(name)\n",
    "    for i in range(len(segsFull)):\n",
    "        print(\"FULL\")\n",
    "        print(segsFull[i])\n",
    "        print(\"INNER\")\n",
    "        print(segsInner[i])\n",
    "        print(\"\\n\\n_______\\n\\n\")\n",
    "        \n",
    "        \n",
    "def inspectRangeOfOldGazettes(startGaz, endGaz, titles = ['THE LAND ACT', 'THE NATIONAL LAND COMMISSION ACT', \n",
    "                                'THE ENIVONRMENTAL MANAGEMENT AND','THE LAND REGISTRATION ACT']):\n",
    "    \"\"\"Debugging method. Print output of many old gazettes.\"\"\"\n",
    "    # Third act is the \"Environmental Management and Conservation Act (2015) (EMCA)\"\n",
    "    \n",
    "    for i in range(startGaz, endGaz):\n",
    "        inspectOldGazette(i, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_default",
   "language": "python",
   "name": "conda-env-py37_default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
