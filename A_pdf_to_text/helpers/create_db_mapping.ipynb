{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests \n",
    "import os\n",
    "\n",
    "from helpers import check_gazette_filenames as cf \n",
    "from helpers import write_urls as wu\n",
    "from helpers import dest_fn_from_url as df\n",
    "\n",
    "FOLDER = \"/home/dssg-cfa/ke-gazettes-first-pgs/\"\n",
    "FOLDER_CURR = \"/home/dssg-cfa/ke-gazettes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The final data structure will have the form: \n",
    "- Key: name in our database\n",
    "- Value: a dictionary with\n",
    "--- src_database: source database(s) (list)\n",
    "--- names_in_db (list)\n",
    "--- checksums: (if connected africa) -- a list, but should just be one of these\n",
    "--- docids: (if connected africa) document id (unique to the document) \n",
    "--- docnums: (if gazeti) document number \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from hash (checksums) and name to doc ID \n",
    "def get_to_id(): \n",
    "    data_json = wu.conn_afr_api_call()\n",
    "    hash_and_name_to_id = {}\n",
    "\n",
    "    for result in data_json['results']: \n",
    "        checksums = result['checksums'][0]\n",
    "        name = result['name']\n",
    "        if (checksums, name) not in hash_and_name_to_id:\n",
    "            hash_and_name_to_id[(checksums, name)] = []\n",
    "        hash_and_name_to_id[(checksums, name)].append(result['id'])\n",
    "    \n",
    "    return hash_and_name_to_id\n",
    "\n",
    "def info_to_std_format(vol, issue, date, special): \n",
    "    if vol.isdigit():\n",
    "        vol = df.num2roman(int(vol))\n",
    "    name = \"gazette-ke-vol-\" + vol.lower() + \"-no-\" + issue + \"-\" + date\n",
    "    if special:\n",
    "        name += \"-special\"\n",
    "    return name.lower()\n",
    "\n",
    "\n",
    "def fn_to_std_format(fn):\n",
    "    checksum = fn[fn.rfind(\"_\") + 1:].replace(\"*\", \"\")\n",
    "    special = \"special\" in fn\n",
    "    fn_trimmed = fn.replace(\"-special\", \"\")\n",
    "    vol = fn_trimmed[fn_trimmed.find(\"vol-\") + 4:fn_trimmed.find(\"-no\")]\n",
    "    no = fn_trimmed[fn_trimmed.find(\"no-\") + 3:fn_trimmed.find(\"-dated\")]\n",
    "    dated = fn_trimmed[fn_trimmed.find(\"dated-\"):fn_trimmed.find(\"_\")]\n",
    "    return info_to_std_format(vol, no, dated, special)\n",
    "\n",
    "\n",
    "def get_true_fn(gazette_data): \n",
    "    vol, issue = cf.is_numbered_correctly(\"\", gazette_data, just_results = True)\n",
    "    if not vol or not issue:\n",
    "        return \"invalid_fn_placeholder\"\n",
    "    date = cf.get_date(gazette_data)\n",
    "    special = cf.is_special_issue(gazette_data)\n",
    "    return info_to_std_format(vol, issue, date, special)\n",
    "\n",
    "\n",
    "def get_info_gazeti(fn, new_fn, gazette_data, fn_mapping): \n",
    "    '''\n",
    "    Given: filepath to first page JSON\n",
    "    Returns: \n",
    "    (1) new filename (directly from Gazette, in our format)\n",
    "    (2) dictionary with appropriate information\n",
    "    '''\n",
    "    fn = fn.replace(FOLDER, \"\")\n",
    "    if new_fn in fn_mapping: \n",
    "        to_src = fn_mapping[new_fn]\n",
    "        if \"docnums\" not in to_src:\n",
    "            to_src[\"docnums\"] = []\n",
    "    else: \n",
    "        to_src = {\"src_database\": [], \"names_in_db\": [], \"docnums\": []}\n",
    "    \n",
    "    if \"gazeti\" not in to_src[\"src_database\"]:\n",
    "        to_src[\"src_database\"].append(\"gazeti\")\n",
    "    \n",
    "    src_name = fn[0:fn.find(\"_\")]\n",
    "    if src_name not in to_src[\"names_in_db\"]:\n",
    "        to_src[\"names_in_db\"].append(src_name)\n",
    "        \n",
    "    num = fn[fn.rfind(\"-\") + 1:]\n",
    "    to_src[\"docnums\"].append(num)\n",
    "    \n",
    "    return to_src\n",
    "\n",
    "    \n",
    "def get_info_conn_af(fn, new_fn, gazette_data, fn_mapping, hash_and_name_to_id): \n",
    "    '''\n",
    "    Given: filepath to first page JSON\n",
    "    Returns: \n",
    "    (1) new filename (directly from Gazette, in our format)\n",
    "    (2) dictionary with appropriate information\n",
    "    '''\n",
    "    fn = fn.replace(FOLDER, \"\")\n",
    "    if new_fn in fn_mapping: \n",
    "        to_src = fn_mapping[new_fn]\n",
    "        if \"checksums\" not in to_src: \n",
    "            to_src[\"checksums\"] = []\n",
    "            to_src[\"docids\"] = []\n",
    "    else: \n",
    "        to_src = {\"src_database\": [], \"names_in_db\": [], \"checksums\": [], \"docids\": []}\n",
    "    \n",
    "    if \"connected-africa\" not in to_src[\"src_database\"]:\n",
    "        to_src[\"src_database\"].append(\"connected-africa\")\n",
    "    \n",
    "    src_name = fn[0:fn.find(\"_\")]\n",
    "    if src_name not in to_src[\"names_in_db\"]:\n",
    "        to_src[\"names_in_db\"].append(src_name)\n",
    "    \n",
    "    checksum = fn[fn.rfind(\"_\") + 1:].replace(\"*\", \"\")\n",
    "    if checksum not in to_src[\"checksums\"]:\n",
    "        to_src[\"checksums\"].append(checksum)\n",
    "    \n",
    "    id_list = hash_and_name_to_id[(checksum, src_name)]\n",
    "    for docid in id_list:\n",
    "        if docid not in to_src['docids']:\n",
    "            to_src['docids'].append(docid)\n",
    "    \n",
    "    return to_src\n",
    "\n",
    "def get_info():\n",
    "    fn_mapping = {}\n",
    "    fn_mapping[\"empty_files\"] = []\n",
    "    failures = []\n",
    "    hash_and_name_to_id = get_to_id()\n",
    "    fns = [f for f in os.listdir(FOLDER)]\n",
    "    fns = [FOLDER + f for f in fns]\n",
    "    curr_fns = [f for f in os.listdir(FOLDER_CURR)]\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for fn in fns: \n",
    "        with open(fn) as f: \n",
    "            gazette_data = json.load(f)\n",
    "        \n",
    "        first_page = gazette_data['analyzeResult']['readResults'][0]['lines']\n",
    "        if len(first_page) == 0:\n",
    "            fn_mapping[\"empty_files\"].append(fn.replace(FOLDER, \"\"))\n",
    "            continue\n",
    "        \n",
    "        new_fn = get_true_fn(gazette_data)\n",
    "        \n",
    "        if new_fn not in curr_fns:\n",
    "            failures.append(fn.replace(FOLDER, \"\"))\n",
    "            continue\n",
    "            \n",
    "        if \"connected-africa\" in fn: \n",
    "            to_src = get_info_conn_af(fn, new_fn, gazette_data, fn_mapping, hash_and_name_to_id)\n",
    "        elif \"gazeti\" in fn: \n",
    "            to_src = get_info_gazeti(fn, new_fn, gazette_data, fn_mapping)\n",
    "        else:\n",
    "            print(\"invalid filename for \" + fn + \"\\n\")\n",
    "            continue\n",
    "            \n",
    "        fn_mapping[new_fn] = to_src\n",
    " \n",
    "    failures = loop_failures(failures, fn_mapping, curr_fns, hash_and_name_to_id)\n",
    "    fn_mapping['failed_to_map_from_cfa_db'] = failures\n",
    "    \n",
    "    print(\"failed on \" + str(len(failures)))\n",
    "    return fn_mapping\n",
    "\n",
    "\n",
    "def loop_failures(failures, fn_mapping, curr_fns, hash_and_name_to_id):\n",
    "    \n",
    "    new_failed = {}\n",
    "    \n",
    "    for fn in failures:\n",
    "        new_fn = fn_to_std_format(fn)\n",
    "        \n",
    "        with open(FOLDER + fn) as f:\n",
    "            gazette_data = json.load(f)\n",
    "         \n",
    "        if cf.is_special_issue(gazette_data): \n",
    "            if \"-special\" not in new_fn: \n",
    "                new_fn += \"-special\" \n",
    "        else: \n",
    "            if \"-special\" in new_fn:\n",
    "                new_fn = new_fn.replace(\"-special\", \"\")\n",
    "        \n",
    "        if new_fn in curr_fns:  \n",
    "            if \"connected-africa\" in fn: \n",
    "                to_src = get_info_conn_af(fn, new_fn, gazette_data, fn_mapping, hash_and_name_to_id) \n",
    "            elif \"gazeti\" in fn:\n",
    "                to_src = get_info_gazeti(fn, new_fn, gazette_data, fn_mapping)\n",
    "            fn_mapping[new_fn] = to_src\n",
    "        else:\n",
    "            new_failed[fn] = new_fn\n",
    "    \n",
    "    return new_failed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_default",
   "language": "python",
   "name": "conda-env-py37_default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
