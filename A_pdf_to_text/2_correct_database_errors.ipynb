{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "file_out_mapping = \"filename_map_to_database.txt\"\n",
    "\n",
    "from helpers import check_gazette_filenames as cf\n",
    "from helpers import json_extraction as je\n",
    "from helpers import write_urls as wu \n",
    "from helpers import dest_fn_from_url as df\n",
    "from helpers import create_db_mapping as db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file walks the user through a process of calling functions to ensure that, as much as possible, all Gazettes in our filesystem are named accurately and that we have no duplicates, and that all text versions of Gazettes can be linked back to where they were originally stored in CFA's database. \n",
    "\n",
    "The **first step** is to rename files to correct potential issues. Some manual error checking is recommended, and this process could definitely be improved.\n",
    "\n",
    "The **second step** is to create a mapping between all files in our database and all files in the original CfA database. It is common for one file in our database to map to multiple files in the original databases. \n",
    "\n",
    "### Step One: rename files to accurately reflect contents\n",
    "\n",
    "Naming issues are described in the \"check_gazette_filenames\" file.\n",
    "\n",
    "Note that \"check_filenames\", called below, will print information and instructions. Manually checking that output is reasonable is highly recommended; and you may approve or deny the rename suggestion. The below will prompt you to approve renaming files to correctly reflect their contents. \n",
    "\n",
    "* The functions for checking special issues (i.e., whether it is a special issue or not) are extremely reliable. \n",
    "* The dated functions are relatively reliable, but we recommend at minimum ensuring that the dates displayed are valid dates.\n",
    "* The volume/issue numbering checks return errors sometimes. We'd recommend manually confirming these -- cross-checking suggested renames with the gazettes in the original database -- especially if the issue or volume numbering only differs by one character (e.g., \"cii\" vs. \"ci\"). \n",
    "\n",
    "Note that, as the `rename_gazettes` code stands, gazettes that are incorrectly labelled as special issues are **automatically renamed** (without prompting). Change this if you would like to be more cautious. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_date_range(f, yr_start, yr_end): \n",
    "    '''\n",
    "    Filter for files dated beginning at yr_start, up to but not including yr_end\n",
    "    '''\n",
    "    for yr in range(yr_start, yr_end + 1): \n",
    "        if str(yr) in f: \n",
    "            return True\n",
    "    return False\n",
    "\n",
    "filepath = \"/home/dssg-cfa/ke-gazettes/\"\n",
    "filename_list = [f for f in os.listdir(filepath) if in_date_range(f, 2000, 2009)]\n",
    "\n",
    "for fn in filename_list:\n",
    "    with open(filepath + fn) as file:\n",
    "        gazette_data = json.load(file)\n",
    "    cf.check_filename(fn, gazette_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Two: create a mapping between filenames in our (\"DSSG\") database and the original CfA databases.\n",
    "\n",
    "This should associate unique filenames in our system with unique document IDs and other identifying information in the CfA systems. This can easily be flipped to access information the other way around. \n",
    "\n",
    "We do this by: \n",
    "* Getting and saving an OCR version of only the first page of all Gazettes\n",
    "* For each Gazette, we then: \n",
    "   + save the metadata\n",
    "   + get the true filename, using the same process as was used to access all filenames (above)\n",
    "\n",
    "We end up with a dictionary with the following structure: \n",
    "* **Key**: Name in our database\n",
    "* **Value** a dictionary with: \n",
    "    + src_database: source database(s) (list) \n",
    "    + names_in_db: names under which the file is stored in the database(s) (list) \n",
    "    + checksums: if src_database includes connected-africa, then the file will have a checksum, or hash value, associated. This is unique to the content, but different PDF scans of the same Gazette may have different hash values. (list)\n",
    "    + docid: if src_database includes connected-africa, then the file will be identified by a unique document id. This is unique to the file in the CfA database; no two files, even if they have the same name and/or same content, have the same document id. (list) \n",
    "    + docnums: if src_database includes gazeti, then the file will be identified by a unique document number. (These have the additional benefit that you can build a URL that redirects to the document PDF out of this number -- see `get_url_gazeti` below.) (list)  \n",
    "* **Additional keys**: \n",
    "    + \"failed_to_map_from_cfa_db\" maps to a dictionary which includes the name in the CfA original database (key) and its filename conversion in our standard format. For these, both the filename taken directly from the OCR'd Gazette and the filename taken from how it is stored in the database do not match with any filenames in our database. \n",
    "    + \"empty_files\": files that are empty in the original database\n",
    "    \n",
    "**We save this map for future reference.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call this to write destination URLs with metadata \n",
    "\n",
    "filepath_out_url_ca = \"/home/dssg-cfa/final_dest_urls/dest_urls_ca_metadata\"\n",
    "wu.write_ca_urls_metadata(filepath_out_url, yr_start = 2000)\n",
    "\n",
    "filepath_out_url_gaz = \"/home/dssg-cfa/final_dest_urls/dest_urls_gazeti_metadata\"\n",
    "wu.write_gazeti_urls_metadata(filepath_out_url, yr_start = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk OCR with first page, resizing as needed\n",
    "# Start with conn. africa database\n",
    "failures_ca = []\n",
    "je.bulk_ocr_first_pg(filepath_out_url_ca, \"connected-africa\", failures_ca)\n",
    "print(failures_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for Gazeti database\n",
    "filepath_out_url_gaz = \"/home/dssg-cfa/final_dest_urls/dest_urls_gazeti_metadata\"\n",
    "failures_gaz = []\n",
    "je.bulk_ocr_first_pg(filepath_out_url_gaz, \"gazeti\", failures_gaz)\n",
    "print(failures_gaz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find issue number; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'No'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find issue number; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find issue number; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "Unable to find string 'Vol'; check manually\n",
      "failed on 17\n"
     ]
    }
   ],
   "source": [
    "# This calls a function that generates the mapping described above, using\n",
    "# information in the first page of the Gazette, metadata stored when \n",
    "# URLs were grabbed, and \"check_filename\" functions. \n",
    "\n",
    "fn_mapping = db.get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the file \n",
    "with open(file_out_mapping, 'w') as f:\n",
    "    json.dump(fn_mapping, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_default",
   "language": "python",
   "name": "conda-env-py37_default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
